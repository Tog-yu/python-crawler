import requests
from bs4 import BeautifulSoup
import re
import time
import pymongo

def getHTML(url):
    try:
        kv = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
        r = requests.get(url,headers = kv)
        r.raise_for_status()
        return r.text
    except:
        print("wrong")

def Bsdata(html):
    data_list = []
    soup = BeautifulSoup(html,"html.parser")
    for each in soup("div",class_= "titlelink box"):
        title = each.a.text.strip()
        link = "https://bbs.hupu.com" + each.a['href']
        author = each.find_next_sibling().a.text.strip()
        authorlink = each.find_next_sibling().a['href']
        browse = each.find_parent().find("span",class_="ansour box").text.strip()
        feedback = browse.split('/')[0].strip()
        view = browse.split('/')[1].strip()
        data_list.append([title,link,author,authorlink,feedback,view])
        # print(feedback,view)
    return data_list



def main(page):
    client = pymongo.MongoClient('localhost')
    db = client.hupu_database
    collection = db.hupu

    url = "https://bbs.hupu.com/bxj-" + str(page)
    print(url)
    html = getHTML(url)
    data_list = Bsdata(html)
    for each in data_list:
        post = {
            "title" : each[0],
            "link" : each[1],
            "author" : each[2],
            "authorlink" : each[3],
            "feedback" : each[4],
            "view" : each[5]
        }
        collection.insert_one(post)
    print(str(page) + "页爬取完成")
    time.sleep(3)


for page in range (1,50):
    main(page)
